{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "777d793c",
   "metadata": {},
   "source": [
    "### section 1.1.5\n",
    "- 对于模型内的数据精度，我们规定输入为fp32，混合为fp16\n",
    "- 可见除了norm其他都是fp16，loss和grad这种为fp32\n",
    "- 训练一般呈现三角形合适，谷底表示优化器状态和模型参数，上升代表activation中间结果被保存，到达最高点是反向传播的开始，往下走是因为act的值不再需要了。\n",
    "- 在T4上我们发现，bf16的策略有问题因为Turing架构不支持autocast的硬件加速，在转换精度时会变慢，因为硬件不兼容，但是峰值是显著降低的15g -> 12g\n",
    "- details降低，显示范围按占用为阈值，部分小的就显示不出来了\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
